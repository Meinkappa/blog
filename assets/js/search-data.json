{
  
    
        "post0": {
            "title": "How to train MNIST with FastAI",
            "content": "After reading chapter 4 of Deep Learning for Coders with Fastai and PyTorch: AI Applications Without a PhD, AKA &quot;Fastbook&quot;, I can train very easily with FastAI. . !pip install -Uqq fastbook . |████████████████████████████████| 720 kB 5.5 MB/s |████████████████████████████████| 46 kB 1.9 MB/s |████████████████████████████████| 1.2 MB 9.1 MB/s |████████████████████████████████| 186 kB 21.1 MB/s |████████████████████████████████| 56 kB 2.7 MB/s |████████████████████████████████| 51 kB 307 kB/s . Although it is discouraged to import * in python progarmming environment, in deep learning enviornment, it is actually encouraged. Rather than importing libraries as needed one by one, it is easier to load everything needed before start exploring. It is better to have it and not need it than need it and not have it. . from fastai.vision.all import * . We are going to use MNIST handwritten data. With FastAI, it is very easy to download data into our path. . path = untar_data(URLs.MNIST) path.ls() . . 100.03% [15687680/15683414 00:06&lt;00:00] (#2) [Path(&#39;/root/.fastai/data/mnist_png/testing&#39;),Path(&#39;/root/.fastai/data/mnist_png/training&#39;)] . Now that we have data, we need a datablock, which is a template for how data should be processed. . . Here is how our template is made: . blocks=(ImageBlock, CategoryBlock) means inputs are images and labels are multiple categories. | get_items=get_image_files specifies it is taking image files. | splitter=RandomSplitter(seed=42) randomly sets aside 20 percent of whole dataset for validation so that we can check for overfitting. Although MNIST dataset already has validation set, we do not have to use as suggested. | get_y=parent_label specifies how our data gets labels from the data. In this dataset, each image&#39;s parent directory informs us what kind of digit it is. | . digits = DataBlock(blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(seed=42), get_y=parent_label) dls = digits.dataloaders(path) . Now that we have the dataloaders, we can take a look at the data with dls.showbatch(). . dls.show_batch() . It looks good. Each image has a correct label. It is time to train our model with the data. Instead of making our models from scratch, we will use pretrained model because we can save time and resources. With cnn_learner, we use resnet18 and set our metrics as error_rate. Then we fine_tune our model, which means we remove the last layer of resnet18 and replace it with our custom one, which will categorize what kind of digit it is. Also, this last layer, which is also called &#39;head&#39;, is the only layer we are training. All other layers remain the same. . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(2) . Downloading: &#34;https://download.pytorch.org/models/resnet18-f37072fd.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /pytorch/c10/core/TensorImpl.h:1156.) return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode) . epoch train_loss valid_loss error_rate time . 0 | 0.724134 | 0.505309 | 0.158071 | 07:06 | . epoch train_loss valid_loss error_rate time . 0 | 0.113460 | 0.064733 | 0.017857 | 14:49 | . 1 | 0.045581 | 0.044138 | 0.013214 | 15:11 | . FastAI will use GPU automatically if it is available. On a google colab GPU server, it took about six minutes to train with error rate close to 1%. . It is very easy to get started with FastAI because everything is already tuned for best practices without us trying to come up with everything in the beginning. When first training a model, this can be a quick baseline for us to compare with. With this baseline, we can figure out how more complex model is performing. .",
            "url": "https://meinkappa.github.io/blog/2021/09/13/MNIST-In-FastAI.html",
            "relUrl": "/2021/09/13/MNIST-In-FastAI.html",
            "date": " • Sep 13, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Car classifier",
            "content": "While reading fastbook chapter 2, I built a bear classifier. Since it was very easy to make and fun, I am making another one with cars. . Instead of using Bing, I am using Duckduckgo search engine. . from fastbook import * urls = search_images_ddg(&#39;Toyota car&#39;, max_images=100) len(urls),urls[0] . (100, &#39;http://cdn.carbuzz.com/gallery-images/1600/790000/200/790204.jpg&#39;) . download_url(urls[0], &#39;images/bear.jpg&#39;) im = Image.open(&#39;images/bear.jpg&#39;) im.thumbnail((256,256)) im . . 102.50% [163840/159843 00:00&lt;00:00] Here are types of cars I am trying to classify. I put m4 sherman tank and go kart for fun. They are very distinct from others and easy to classify. However, it will be harder to classify among toyota camry, kia forte, and tesla model x. The biggest challenge will be classifying between toyota camry and kia forte as they are similiar than others. . car_types = &#39;toyota camry&#39;, &#39;kia forte&#39;, &#39;go kart&#39;, &#39;tesla model x&#39;, &#39;m4 sherman&#39; path = Path(&#39;cars&#39;) . After training a model with 100 images each category, the model confused a lot between toyota camry and kia forte. Even after cleaning data and using deeper architectures such as resnet34 and resnet50, it did not perform much better. Therefore, I am trying to gather 200 images for just toyota camry and kia forte and see what happens. . def download_more_images(title, data_types, path, num_imgs=100, more_imgs=None, more_num_imgs=200): if not path.exists(): path.mkdir() for o in data_types: dest = (path/o) dest.mkdir(exist_ok=True) if more_imgs != None and o in more_imgs: max_imgs = more_num_imgs else: max_imgs = num_imgs results = search_images_ddg(f&#39;{o} {title}&#39;, max_images=max_imgs) download_images(dest, urls=results) . download_more_images(&#39;car&#39;, car_types, path, more_imgs=[&#39;toyota camry&#39;, &#39;tesla model x&#39;], more_num_imgs=300) . fns = get_image_files(path) fns . (#1023) [Path(&#39;cars/go kart/00000068.jpg&#39;),Path(&#39;cars/go kart/00000023.jpg&#39;),Path(&#39;cars/go kart/00000044.JPG&#39;),Path(&#39;cars/go kart/00000014.jpg&#39;),Path(&#39;cars/go kart/00000022.jpg&#39;),Path(&#39;cars/go kart/00000018.jpg&#39;),Path(&#39;cars/go kart/00000064.jpg&#39;),Path(&#39;cars/go kart/00000088.jpg&#39;),Path(&#39;cars/go kart/00000078.jpg&#39;),Path(&#39;cars/go kart/00000052.jpg&#39;)...] . We clean up images that cannot be opened. . failed = verify_images(fns) failed . (#10) [Path(&#39;cars/m4 sherman/00000097.jpg&#39;),Path(&#39;cars/tesla model x/00000096.jpg&#39;),Path(&#39;cars/toyota camry/00000214.jpg&#39;),Path(&#39;cars/toyota camry/00000185.jpg&#39;),Path(&#39;cars/toyota camry/00000166.jpg&#39;),Path(&#39;cars/toyota camry/00000091.jpg&#39;),Path(&#39;cars/kia forte/00000038.jpg&#39;),Path(&#39;cars/kia forte/00000092.jpg&#39;),Path(&#39;cars/kia forte/00000094.jpg&#39;),Path(&#39;cars/kia forte/00000082.jpg&#39;)] . failed.map(Path.unlink); . Sidebar: Getting Help in Jupyter Notebooks . End sidebar . From Data to DataLoaders . First, we create a template for our data, which is DataBlock. From here, we specify what kind of data for what purpose (image for classification), how to get items (get image files), how big is the validation set (20% with random seed), how to label data (name of parent directory), and how to transform our data (resize them into 128 pixels). . cars = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . Now that we have a datablock, we feed in data to build a dataloader. . dls = cars.dataloaders(path) . We can check images with show_batch. Oops! There is a problem with our images. After resizing images, we lost some details of them. It is easy to fix it by squishing those images into our desired size. . dls.valid.show_batch(max_n=10, nrows=2) . We fit all the detail in each image, but some images do not reflect how they actually look. . cars = cars.new(item_tfms=Resize(128, ResizeMethod.Squish)) dls = cars.dataloaders(path) dls.valid.show_batch(max_n=4, nrows=1) . Padding zeros for the border allows us to have our images look as they actually are, but it is a waste of computation. . cars = cars.new(item_tfms=Resize(128, ResizeMethod.Pad, pad_mode=&#39;zeros&#39;)) dls = cars.dataloaders(path) dls.valid.show_batch(max_n=4, nrows=1) . So, as images get randomly cropped, we get a partial representation of vehicles. . cars = cars.new(item_tfms=RandomResizedCrop(128, min_scale=0.3)) dls = cars.dataloaders(path) dls.train.show_batch(max_n=4, nrows=1, unique=True) . Data Augmentation . With that, we can come up with a data augmentation, which allows us to look at images with different angles. That means, how they actually look in the real world. With this technique, we can use little data and still get a great result. . cars = cars.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2)) dls = cars.dataloaders(path) dls.train.show_batch(max_n=8, nrows=2, unique=True) . /usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1023: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release. torch.linalg.solve has its arguments reversed and does not return the LU factorization. To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack. X = torch.solve(B, A).solution should be replaced with X = torch.linalg.solve(A, B) (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:760.) ret = func(*args, **kwargs) . Training Your Model, and Using It to Clean Your Data . cars = cars.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = cars.dataloaders(path) . learn = cnn_learner(dls, resnet101, metrics=error_rate) learn.fine_tune(5) . Downloading: &#34;https://download.pytorch.org/models/resnet101-63fe2227.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /pytorch/c10/core/TensorImpl.h:1156.) return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode) . epoch train_loss valid_loss error_rate time . 0 | 1.613251 | 0.601070 | 0.168317 | 01:05 | . /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . . 40.00% [2/5 02:18&lt;03:27] epoch train_loss valid_loss error_rate time . 0 | 0.605177 | 0.352259 | 0.113861 | 01:09 | . 1 | 0.441147 | 0.239060 | 0.069307 | 01:08 | . . 83.33% [10/12 00:47&lt;00:09 0.3445] &lt;/div&gt; &lt;/div&gt; /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . epoch train_loss valid_loss error_rate time . 0 | 0.605177 | 0.352259 | 0.113861 | 01:09 | . 1 | 0.441147 | 0.239060 | 0.069307 | 01:08 | . 2 | 0.321818 | 0.185381 | 0.039604 | 01:10 | . 3 | 0.248389 | 0.188398 | 0.039604 | 01:08 | . 4 | 0.197988 | 0.173784 | 0.049505 | 01:08 | . /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . interp.plot_top_losses(10, nrows=2) . With cleaner, we can see which images are mislabelled or incorrect. After checking and marking which ones to delte with and which ones to move with other categories, we run next lines of code because this marking does not actually delete or move anything.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; cleaner = ImageClassifierCleaner(learn) cleaner . /usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images &#34;Palette images with Transparency expressed in bytes should be &#34; . These lines of code modify files in our path. . Turning Your Model into an Online Application . Using the Model for Inference . Now, we can export our result with learn.export((). This gives us everything we need in order to use it in production, such as the architecture we trained with, and trained parameters. Also, we get a template of how to create DataLoaders, which is DataBlock. This way, we do not have to redefine how to transform our data. . learn.export() . path = Path() path.ls(file_exts=&#39;.pkl&#39;) . (#1) [Path(&#39;export.pkl&#39;)] . !ls . cars export.pkl gdrive images sample_data . Although we already have learn object, here is how to use the exported pickle file. By using load_learner, we can get a learn object, which allows us to predict with any image with given categories. . learn_inf = load_learner(path/&#39;export.pkl&#39;) . learn_inf.predict(&#39;images/bear.jpg&#39;) . (&#39;tesla model x&#39;, tensor(3), tensor([3.1992e-05, 1.1194e-02, 2.2749e-04, 9.0126e-01, 8.7283e-02])) . learn_inf.dls.vocab . [&#39;go kart&#39;, &#39;kia forte&#39;, &#39;m4 sherman&#39;, &#39;tesla model x&#39;, &#39;toyota camry&#39;] . Creating a Notebook App from the Model . This is an easy way to make a notebook app. With an upload button, a user can upload a file, then click classify to get a result with how confident the model is. . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn_inf.predict(img) . lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . btn_run = widgets.Button(description=&#39;Classify&#39;) btn_run . def on_click_classify(change): img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; btn_run.on_click(on_click_classify) . VBox([widgets.Label(&#39;Select your car!&#39;), btn_upload, btn_run, out_pl, lbl_pred]) . Ultimately, it is just using learn_inf.predict method. By using this simple code, we can potentially build any web or mobile applications. . &lt;/div&gt; .",
            "url": "https://meinkappa.github.io/blog/2021/09/06/Car-Classifier.html",
            "relUrl": "/2021/09/06/Car-Classifier.html",
            "date": " • Sep 6, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Training a model with pure python (different approach from using classes)",
            "content": "This time, instead of using classes, I am trying a different approach, which is by just using functions. This is neither flexible nor expandable as using classes. Also, it is more cumbersome to write it this way as each parameter needs to be tracked and passed manually. Although I could write with type dispatch and layer abstraction, I just wanted to get it over with a bare bone working model and worry about expanding it later. . import gzip import matplotlib.pyplot as plt import random import statistics import math import operator as op import time from functools import reduce . It is pretty much the same program until the model part. . Utilities . Because we are only using python lists, we need to build utilities or tools we need in order to train our model. First, I start with shape, which returns a tuple of shape of a matrix or a list . def shape(t) -&gt; tuple: &quot;Using for loop to go deeper, but only goes up to 10 layers.&quot; # It only works up to 10 levels of deep res = tuple() for i in range(0, 10): try: # Using eval is very slow. I gotta come up with other way to do this. res += (len(eval(&#39;t&#39;+str(&#39;[0]&#39;*i))),) except TypeError: # print(&#39;Not a list&#39;) break except IndexError: print(&#39;Cant index it&#39;) break return res . def shape(t) -&gt; tuple: &quot;&quot;&quot; It uses while loop to go through so that we are not limited to 10. However, using i to keep up with a value does not seem too pythonic. &quot;&quot;&quot; res = tuple() i = 0 while True: try: # Using eval is very slow. I gotta come up with other way to do this. res += (len(eval(&#39;t&#39;+str(&#39;[0]&#39;*i))),) # print(&#39;t&#39;+str(&#39;[0]&#39;*i), &#39; eval is &#39;, len(eval(&#39;t&#39;+str(&#39;[0]&#39;*i)))) except TypeError: # print(&#39;Not a list&#39;) break except IndexError: print(&#39;Cant index it&#39;) break i += 1 return res . def shape(t) -&gt; tuple: &quot;&quot;&quot; More elegent way to approach. &quot;&quot;&quot; def loop(mat, result): if not isinstance(mat, list): return result else: return loop(mat[0], result + (len(mat),)) return loop(t, tuple()) . Still works as well . shape([1, 2, 3]), shape([[1, 2, 3], [4, 5, 6]]) . ((3,), (2, 3)) . Now that we have a way of getting a shape of a matrix, we can move onto map_mat, which takes a function and a vector or a matrix. It calls the function and mapping into a matrix or a vector. . def map_mat(fn, mat): &quot;Apply fn into a matrix or a vector&quot; res = [] if len(shape(mat)) == 2: # It is a matrix for i in range(len(mat)): res.append([fn(m) for m in mat[i]]) else: # It is a vector return list(map(fn, mat)) return res . lst = [1, 2, 3, 4, 5] mat1 = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] . map_mat(lambda x: x + 1, lst) . [2, 3, 4, 5, 6] . map_mat(lambda x: x + 1, mat1) . [[2, 3, 4], [5, 6, 7], [8, 9, 10]] . Instead of using for loops, it is faster to use list comprehension. . def map_mat2(fn, mat): &quot;A little faster than map_mat.&quot; return [list(map(fn, mat[i])) for i in range(len(mat))] . . . It would be better if we can make matrices easier instead of making them by hand. . def lst_nums(shape, num=1): &quot;Use optional num to define what a list is full of. Default is 1&quot; if isinstance(shape, tuple): x, y = shape return [[num]*y for _ in range(x)] else: x = shape return [num]*x . hund_1s = lst_nums((10, 10), 1) len(hund_1s), len(hund_1s[0]) . (10, 10) . hund_1s . [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]] . This one gets random numbers. . def lst_random(shape, init_parms=False): &quot;return a list of randoms and if init_parms is True, initialize parameters using Kaiming init.&quot; x, y = shape res = lst_nums(shape, 0) for i in range(x): for j in range(y): res[i][j] = random.normalvariate(0,1) if init_parms: res[i][j] *= math.sqrt(2/x) return res . rand_mat = lst_random((10,10)) shape(rand_mat) . (10, 10) . Here is transpose function, which transposes a matrix. . def transpose (mat): &quot;Transpose the matrix&quot; return [[m[i] for m in mat] for i in range(len(mat[0]))] . Now that we can make matrices with ease, we need a function that can be called using multiple matrices. With elementwise function, we can call a function with inputs from two matrices elementwise. This is very useful function when it comes to training a model later on. . def elementwise (fn, mat1, mat2): &quot;Closure that returns function that does element wise action&quot; # can it handle (64,), (64,)? YES! mat = [] try: m1r,m1c = shape(mat1) except ValueError: m1r = shape(mat1)[0] m1c = 0 try: m2r,m2c = shape(mat2) except ValueError: m2r = shape(mat2)[0] m2c = 0 if m1c == m2c == 0: # Two 1D vectors return list(map(fn, mat1, mat2)) elif (m1r, m1c) == (m2r, m2c): # two matrixs with same sizes return [[fn(x,y) for x,y in zip(mat1[i], mat2[i])] for i in range(len(mat1))] elif m1c == m2r and m2c==0: # shape of (a, b), (b,) for i in range(m1r): mat.append([fn(x,y) for x,y in zip(mat1[i],mat2)]) return mat elif m1r == m2r and m2c == 0: # shape of (a, b), (a,) for i in range(m1r): mat.append([fn(m, mat2[i]) for m in mat1[i]]) return mat else: assert False, &quot;WTF??&quot; . hund_2s = lst_nums((10, 10), 2) . elementwise(lambda x, y: x+y, hund_1s, hund_2s) . [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]] . rand_mat[0] . [-0.5530030250562127, -0.9095684272234024, 0.3020748692896096, 0.5823743868390977, 1.1346295147026815, -0.2642603973797358, 0.9610147828440702, 0.293583831352499, -0.7606877359378155, -1.453174270668391] . . Now, we need to reshape our matrices into whatever shape we want. . def reshape(matrix, new_shape) -&gt; list: &quot;&quot;&quot; If matrix can be reshaped into new_shape, then return a new matrix with a respective shape. Only supports matrices into 2 dimensional arrays.&quot;&quot;&quot; old_shape = shape(matrix) elem_nums = mul(old_shape) if old_shape == new_shape: return matrix elif not elem_nums == mul(new_shape): raise Exception(&quot;Wrong shape!&quot;) else: return shaping(flatten(matrix), new_shape, elem_nums, list()) . def mul(lst: list) -&gt; int: &quot;&quot;&quot; Return a result of all numbers multiplied. Like sum, but multiplying. &quot;&quot;&quot; return reduce(op.mul, lst, 1) . def shaping(flat, new_shape, elem_nums, result): if len(new_shape) == 0: return result else: div = elem_nums // new_shape[0] for i in range(new_shape[0]): result.append(flat[(i * div):((i+1) * div)]) return result . def flatten(matrix): &quot;&quot;&quot; Flatten a matrix into a 1 dimensional list. &quot;&quot;&quot; result = [] for i in range(len(matrix)): if isinstance(matrix[i], list): result.extend(flatten(matrix[i])) else: result.append(matrix[i]) return result . Testing new tools . shaping(flatten([1, [2, [[[4]]]], 3]), (2,2), 4, []) . [[1, 2], [4, 3]] . shape(flatten(hund_1s)) . (100,) . shape(reshape(hund_1s, (100, 1))), shape(reshape(hund_1s, (1, 100))) . ((100, 1), (1, 100)) . mat3 = [[[1, 2], [3, 4]], [[5, 6], [7, 8]]] mat3, shape(mat3) . ([[[1, 2], [3, 4]], [[5, 6], [7, 8]]], (2, 2, 2)) . shape(reshape(mat3, (4, 2))), reshape(mat3, (4, 2)) . ((4, 2), [[1, 2], [3, 4], [5, 6], [7, 8]]) . Collecting Data . First, we need data if we want to do some training. We are using mnist dataset from yann lecun website. The dataset has training images and testing/validating images. . !wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz !wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz !wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz !wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz . --2021-09-06 04:05:43-- http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz Resolving yann.lecun.com (yann.lecun.com)... 172.67.171.76, 104.21.29.36, 2606:4700:3034::6815:1d24, ... Connecting to yann.lecun.com (yann.lecun.com)|172.67.171.76|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 9912422 (9.5M) [application/x-gzip] Saving to: ‘train-images-idx3-ubyte.gz’ train-images-idx3-u 100%[===================&gt;] 9.45M 7.58MB/s in 1.2s 2021-09-06 04:05:44 (7.58 MB/s) - ‘train-images-idx3-ubyte.gz’ saved [9912422/9912422] --2021-09-06 04:05:44-- http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz Resolving yann.lecun.com (yann.lecun.com)... 172.67.171.76, 104.21.29.36, 2606:4700:3034::6815:1d24, ... Connecting to yann.lecun.com (yann.lecun.com)|172.67.171.76|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 28881 (28K) [application/x-gzip] Saving to: ‘train-labels-idx1-ubyte.gz’ train-labels-idx1-u 100%[===================&gt;] 28.20K --.-KB/s in 0s 2021-09-06 04:05:44 (408 MB/s) - ‘train-labels-idx1-ubyte.gz’ saved [28881/28881] --2021-09-06 04:05:44-- http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz Resolving yann.lecun.com (yann.lecun.com)... 172.67.171.76, 104.21.29.36, 2606:4700:3034::6815:1d24, ... Connecting to yann.lecun.com (yann.lecun.com)|172.67.171.76|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 1648877 (1.6M) [application/x-gzip] Saving to: ‘t10k-images-idx3-ubyte.gz’ t10k-images-idx3-ub 100%[===================&gt;] 1.57M --.-KB/s in 0.05s 2021-09-06 04:05:44 (30.0 MB/s) - ‘t10k-images-idx3-ubyte.gz’ saved [1648877/1648877] --2021-09-06 04:05:44-- http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz Resolving yann.lecun.com (yann.lecun.com)... 172.67.171.76, 104.21.29.36, 2606:4700:3034::6815:1d24, ... Connecting to yann.lecun.com (yann.lecun.com)|172.67.171.76|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 4542 (4.4K) [application/x-gzip] Saving to: ‘t10k-labels-idx1-ubyte.gz’ t10k-labels-idx1-ub 100%[===================&gt;] 4.44K --.-KB/s in 0s 2021-09-06 04:05:44 (611 MB/s) - ‘t10k-labels-idx1-ubyte.gz’ saved [4542/4542] . Here, I convert zip files into image objects with functions I got from here. I am only using numpy library for only conversion purposes. . def mnist_images(fname:str, pct=1) -&gt; list: &quot;&quot;&quot; Convert zip files into lists of images. Only returning pct percent of data. &quot;&quot;&quot; with gzip.open(&#39;data/&#39;+fname, &#39;r&#39;) as f: # first 4 bytes is a magic number magic_number = int.from_bytes(f.read(4), &#39;big&#39;) # second 4 bytes is the number of images image_count = int.from_bytes(f.read(4), &#39;big&#39;) # image_count = int(image_count * percent) # third 4 bytes is the row count row_count = int.from_bytes(f.read(4), &#39;big&#39;) # fourth 4 bytes is the column count column_count = int.from_bytes(f.read(4), &#39;big&#39;) # rest is the image pixel data, each pixel is stored as an unsigned byte # pixel values are 0 to 255 image_data = f.read() images = reshape(list(image_data), (image_count, column_count, row_count)) return images[:int(image_count * pct)] # return reshape(images, (image_count, column_count, row_count)) def mnist_labels(fname:str, pct=1) -&gt; list: &quot;&quot;&quot; Convert zip files into lists of labels. Only returning pct percent of data. &quot;&quot;&quot; with gzip.open(&#39;data/&#39;+fname, &#39;r&#39;) as f: # first 4 bytes is a magic number magic_number = int.from_bytes(f.read(4), &#39;big&#39;) # second 4 bytes is the number of labels label_count = int.from_bytes(f.read(4), &#39;big&#39;) # rest is the label data, each label is stored as unsigned byte # label values are 0 to 9 label_data = f.read() labels = list(label_data) return labels[:int(label_count * pct)] . Now, I am making a directory for all the data and putting data inside. . !mkdir data !mv train-images-idx3-ubyte.gz data !mv train-labels-idx1-ubyte.gz data !mv t10k-images-idx3-ubyte.gz data !mv t10k-labels-idx1-ubyte.gz data !ls data/ . mkdir: cannot create directory ‘data’: File exists t10k-images-idx3-ubyte.gz train-images-idx3-ubyte.gz t10k-labels-idx1-ubyte.gz train-labels-idx1-ubyte.gz . Now that we have the data we need, let&#39;s make this data more usable by using functions that I got above, such as mnist_images and mnist_labels. With mnist_images, I get numpy arrays of images, and with mnist_labels, I get numpy arrays with labels for each image. . py_imgs = mnist_images(&#39;train-images-idx3-ubyte.gz&#39;) py_train_labels = mnist_labels(&#39;train-labels-idx1-ubyte.gz&#39;) py_test_imgs = mnist_images(&#39;t10k-images-idx3-ubyte.gz&#39;) py_test_labels = mnist_labels(&#39;t10k-labels-idx1-ubyte.gz&#39;) . Now that we have numpy arrays of images and labels, we can convert those into python lists. . type(py_imgs[0]) . list . type(py_imgs[0][0]) . int . type(py_imgs), type(py_train_labels) . (list, list) . Data preperation . Now that we have some tools to work with, we can prepare our data for training. First, we will reshape our data. Even if we are not using GPU to train, it is still fun to reshape them. Then, we divide our data by 255 because the highest value is 255. . py_imgs = map_mat2(lambda x: x / 255, py_imgs) py_test_imgs = map_mat2(lambda x: x / 255, py_test_imgs) shape(py_imgs), shape(py_test_imgs) . ((60000, 784), (10000, 784)) . We have a dataset now. Nowe we can: . Train with dataset. | Get predictions and find loss. | Get metrics. | Get gradients and update parameters (weight and bias). | . Matrix multiplication . Now that we have a dataset, it is time to look at matrix multiplication, which is the most important operation in deep learning. First, we initialize weights and bias. . x = lst_random((200,100)) . x[1][:5] . [-0.8688272654033332, 1.8085790495269864, -0.25877003105563723, 0.567414088587352, 0.6784608990427029] . If shape is (2,3): [[1,1,1], [1,1,1]] Also, if matrix multiplication between (2, 3) and (3, 4) should be (2, 4) . def py_matmul(a,b): &quot;Needs some speed ups&quot; ar,ac = len(a),len(a[0]) br,bc = len(b),len(b[0]) assert ac == br, f&#39;Size of ar ({ac}) does not match br ({br}).&#39; c = lst_nums((ar, bc), 0) for i in range(ar): for j in range(bc): for z in range(ac): c[i][j] += a[i][z] * b[z][j] return c . m1 = [[1,2],[3,4]] m2 = [[2,3],[4,5]] m5 = [[1,2,3,4],[5,6]] . py_matmul(m1,m2) . [[10, 13], [22, 29]] . This is not . ml1 = lst_random((784, 100)) ml2 = lst_random((100, 10)) . It works, but it is slow. We can make it faster by getting rid of for loop. . . def col_mat (mat:list, col:int) -&gt; list: &quot;Get a column of a matrix.&quot; return [m[col] for m in mat] . def py_matmul2(a,b): &quot;Use sum function&quot; ar,ac = len(a),len(a[0]) br,bc = len(b),len(b[0]) assert ac == br, f&#39;Size of ar ({ac}) does not match br ({br}).&#39; c = lst_nums((ar, bc), 0) for i in range(ar): for j in range(bc): c[i][j] = sum(elementwise(op.mul, a[i], col_mat(b,j))) return c . py_matmul2(m1, m2) . [[10, 13], [22, 29]] . Using two for loops is faster than using three. . . def py_matmul3(a, b): ar,ac = len(a),len(a[0]) br,bc = len(b),len(b[0]) assert ac == br, f&#39;Size of ar ({ac}) does not match br ({br}).&#39; c = lst_nums((ar, bc), 0) for i in range(ar): c[i] = [sum(elementwise(op.mul, a[i], col_mat(b,j))) for j in range(bc)] return c . py_matmul3(m1, m2) . [[10, 13], [22, 29]] . . . Even with reducing it to one loop, we did not really gain much speed. After using prun, we can see that elementwise is using a lot of time. We can probably get away without using elemtwise to achieve matrix multiplication. . def py_matmul4(a, b): ar,ac = len(a),len(a[0]) br,bc = len(b),len(b[0]) assert ac == br, f&#39;Size of ar ({ac}) does not match br ({br}).&#39; c = lst_nums((ar, bc), 0) t = transpose(b) for i in range(ar): c[i] = [sum(map(lambda x: x[0] * x[1], zip(a[i], (t[j])))) for j in range(bc)] return c . py_matmul4(m1, m2) . [[10, 13], [22, 29]] . Without elementwise, we gained some speed compared to other versions. . . . I am still not satisfied with the result yet. I am sure we can do better. Let&#39;s get some help from itertools. . Default sum takes the longest time to execute now, but it is faster option we have, compared to using for loop or reduce function. . def py_matmul5(a, b): ar,ac = len(a),len(a[0]) br,bc = len(b),len(b[0]) assert ac == br, f&#39;Size of ar ({ac}) does not match br ({br}).&#39; c = lst_nums((ar, bc), 0) t = transpose(b) for i in range(ar): # c[i] = [sum(itertools.starmap(op.mul, zip(a[i], (t[j])))) for j in range(bc)] c[i] = [sum(map(op.mul, a[i], t[j])) for j in range(bc)] return c . py_matmul5(m1, m2) . [[10, 13], [22, 29]] . . . . sum_test = list(range(10_000_000)) len(sum_test) . 10000000 . . def reduce_sum(lst): return functools.reduce(op.add, lst) . . . def for_sum(lst): res = 0 for i in range(len(lst)): res += lst[i] return res . . Time to start initializing stuff . Using Kaiming init. With Kaiming init, we get a head start compared to using just random numbers. . sample = lst_random((200, 100), True) # x = map_mat(lambda x: x*0.1, x) # statistics.stdev(x[0]) . Checking whether the initialization works. Standard deviation should equal to sqrt(2/n_in), and mean should be 0. And this works. With this initialization, we can train deeper layers. For more information, paper is here. . def check_dist(x): for i in range(len(x)//10): print(statistics.stdev(x[i]), statistics.mean(x[i])) . math.sqrt(2/200) . 0.1 . statistics.variance(sample[0]) . 0.01166835954392622 . check_dist(sample) . 0.10802018118817529 0.006734839580310397 0.09979066438587844 0.008812399914570862 0.09561800666605291 0.0036588102360581225 0.10630479135367477 -0.003487502532153677 0.09248731188956884 -0.009716265930764214 0.08925164982494319 0.002461174983794089 0.09004779828472535 -0.0047740753157285735 0.09183294992947737 -0.002294291735614679 0.0902206946359696 0.011964423567947129 0.09353365911746268 -0.00776034955964066 0.09540527003917385 -0.017395048783590796 0.09288727053265064 -0.00665843034626196 0.09575932256030731 0.007674404406812508 0.09784941208555885 -0.01227295035912054 0.08019985251384976 0.019423068155842046 0.10362223714698182 -0.0006158280838981295 0.10775417796667473 0.004915882944669266 0.11004148373690859 0.004351874578332842 0.10544010038322081 0.015143645961911966 0.08509549758228865 0.005024562216006507 . shape(m1), shape(m2) . ((2, 2), (2, 2)) . Model . Now, it is time to diverge from using classes. . def relu(old_x): return 0 if old_x &lt; 0 else old_x . def relu_b (old_x, grad): return grad if old_x &gt; 0 else 0 . def softmax (inp): mat = map_mat2(math.exp, inp) res = [] for i in range(len(mat)): s = sum(mat[i]) res.append([x/s for x in mat[i]]) return res . def softmax_b(old_y, grad): res = elementwise(op.mul, old_y, grad) res = [sum(res[i]) for i in range(len(old_y))] # shape is (64,) return elementwise(op.mul, old_y, elementwise(op.sub, grad, res)) . def crossentropyloss(inp, targ): mat = inp res = [] for i in range(len(mat)): for j in range(len(targ[0])): if targ[i][j] == 1: res.append(-math.log(mat[i][j])) return res . def crossen_b(old_x, old_y): mat = map_mat2(lambda x: x if x&gt;1e-8 else 1e-8, old_x) res = lst_nums(shape(old_x), num=0.) for i in range(len(mat)): for j in range(len(old_y[0])): if old_y[i][j] == 1: res[i][j] = (-1/(mat[i][j])) return res . def linear(x, w, b): return elementwise(lambda x,y: x+y, py_matmul5(x, w), b) . def linear_b(old_x, w, grad): grad_b = mean_0(grad) grad_w = py_matmul5(transpose(old_x), grad) out = py_matmul5(grad, transpose(w)) return out, grad_w, grad_b . def mean_0 (matrix): &quot;Find a mean in matrix over 0 axis&quot; return [statistics.mean([m[i] for m in matrix]) for i in range(len(matrix[0]))] . Data Loader . Now, we will take mini bathces of data with batch size and train. . def prep_data(size): xb = py_imgs[:size] yb = lst_nums((size, 10), 0) yb_vals = py_train_labels[:size] for i in range(size): yb[i][yb_vals[i]] = 1 return xb, yb . x, y = prep_data(25600) shape(x), shape(y) . ((25600, 784), (25600, 10)) . def forward_and_backward(inp, targ, w1, b1, w2, b2): # Forward pass l1 = linear(inp,w1,b1) l2 = map_mat2(relu, l1) sm_old_y = linear(l2,w2,b2) cel_old_x = softmax(sm_old_y) cel_old_x = map_mat2(lambda x: x if x&gt;1e-8 else 1e-8, cel_old_x) # Calculate loss loss = crossentropyloss(cel_old_x, targ) total_loss = sum(loss) / len(targ) # Backward pass grad = crossen_b(cel_old_x, targ) grad = softmax_b(cel_old_x,grad) grad, grad_w2, grad_b2 = linear_b(l2,w2,grad) grad = elementwise(relu_b,l1,grad) grad, grad_w1, grad_b1 = linear_b(inp,w1,grad) return (grad_w1, grad_b1, grad_w2, grad_b2), total_loss, w1, b1, w2, b2 . def make_prediction(inp, w1, b1, w2, b2): inp = reshape(inp, (1, 784)) l1 = linear(inp,w1,b1) l2 = map_mat2(relu, l1) sm_old_y = linear(l2,w2,b2) result = softmax(sm_old_y) result = result[0] return result.index(max(result)) . w1 = lst_random((784, 56), True) w2 = lst_random((56, 10), True) b1 = lst_nums(56, 0) b2 = lst_nums(10, 0) wbs = (w1, b1, w2, b2) . Time to train . With our data set, it took me about five minutes to run on google colab. . def train (n, x=x, y=y, bs=64, lr=0.01): &quot;&quot;&quot; Train n times and return weights and biases &quot;&quot;&quot; # Initialize weights and biases w1 = lst_random((784, 56), True) w2 = lst_random((56, 10), True) b1 = lst_nums(56, 0) b2 = lst_nums(10, 0) wbs = (w1, b1, w2, b2) for i in range(n): for j in range(len(x) // bs): xb = x[j*bs:(j+1)*bs] yb = y[j*bs:(j+1)*bs] # Do a forward and backward then get grad grads, loss, w1, b1, w2, b2 = forward_and_backward(xb, yb, w1, b1, w2, b2) # multiply grads with lr and update weights and biases grads = [map_mat(lambda x: x*lr, mat) for mat in grads] w1 = elementwise(op.sub, w1, grads[0]) b1 = elementwise(op.sub, b1, grads[1]) w2 = elementwise(op.sub, w2, grads[2]) b2 = elementwise(op.sub, b2, grads[3]) if j % 50 == 0: accuracy = len(list(filter(None, [make_prediction(py_test_imgs[i], w1, b1, w2, b2) == py_test_labels[i] for i in range(100)]))) print(f&quot; Batch #{j} with Loss is {loss}, Accuracy is {accuracy}%&quot;) print(f&quot;Epoch:{i+1} / {n} Loss is {loss}, Accuracy is {accuracy}%&quot;) return (w1, b1, w2, b2) . w1, b1, w2, b2 = train(1, lr=0.01) . Batch #0 with Loss is 2.475803253480892, Accuracy is 23% Batch #50 with Loss is 0.3799100496437877, Accuracy is 84% Batch #100 with Loss is 0.301192444492659, Accuracy is 85% Batch #150 with Loss is 0.1791625203831289, Accuracy is 88% Batch #200 with Loss is 0.31264124488813166, Accuracy is 92% Batch #250 with Loss is 0.6165029402332128, Accuracy is 92% Batch #300 with Loss is 0.3882126307826228, Accuracy is 92% Batch #350 with Loss is 0.1822258815469942, Accuracy is 97% Epoch:1 / 1 Loss is 0.2832947414296976, Accuracy is 97% . This approach is not as expandable and flexible as class approach. I could have written as packages of functions consisting forward and backward versions. Then, dispatch either backward or forward depending on the type we need to call. We do not need a functionality of classes or objects in order to write code in objective style. I will rewrite this code later in that manner. .",
            "url": "https://meinkappa.github.io/blog/2021/09/05/Another-Neural-Net.html",
            "relUrl": "/2021/09/05/Another-Neural-Net.html",
            "date": " • Sep 5, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Deep learning with standard Python",
            "content": "Here, we will be traing a deep learning model with only Python. The only 3rd party libary I will be using is matplotlib to show images. This is my first neural net I wrote. If you see some kind of error, please let me know through this email: shipalnomoo at gmail.com. This is a quick hands on exercise. Rather than focusing on theory, this is more hands on to feel what it is to train a model. we will explore what it means to train a model using MNIST handwritten dataset. When I was reading a blog post from Sylvain Gugger called, &quot;A simple neural net in numpy,&quot; I found it interesting and wanted to try to write my version in standard Python. . There are many libraries used for deep learning, such as Tensorflow and Keras, Pytorch, Scikit-Learn, numpy, and others. However, in order to understand basic concept of deep learning, we do no need to use any of these tools. . Here are Python libraries I will be using. Other than matplotlib, all libraries are here: . import gzip # Converting zip into python objects import matplotlib.pyplot as plt # Library for showing images import random # Initializing random weights import statistics # Getting mean or stdev import math # Exponential function import operator as op # just algebraic operators such as +, -, *, / import time # Timing for performance from functools import reduce . Utilities . This section can be skipped as you can understand how deep learning works without understanding how these utilities work. You can consider these as built-in functions or machine language blobs. Simply fold the heading and run it. . If you decided to dig into lower level of deep learning, let&#39;s begin. Because we are only using python lists, we need to build utilities or tools we need in order to train our model. With other fancy libraries, these are built-in. However, because we are building up from scratch, we start with those basic utilities that we will use later on. How these are implemented specifically are not important at all for our purpose of understanding how deep learning works. As long as you get the general idea of what these functions do, that is good enough. However, please do not just run those cells without thinking about what they will return in advance if you want to understand more. Give yourself couple seconds to think and come up with output in your head. This will change your level of understanding. . With those low level functions, we will build up abstraction layers. First, I start with shape, which returns a tuple of shape of a matrix or a list. . def shape(matrix) -&gt; tuple: &quot;&quot;&quot; Get a shape of a matrix &quot;&quot;&quot; def loop(mat, result): if not isinstance(mat, list): return result else: return loop(mat[0], result + (len(mat),)) return loop(matrix, tuple()) . shape([1, 2]) . (2,) . shape([[1, 2, 3], [4, 5, 6]]) . (2, 3) . shape([[[1, 2], [3, 4]]]) . (1, 2, 2) . It would be better if we can make matrices easier instead of making them by hand. . def lst_nums(shape:tuple, num:int=1) -&gt; list: &quot;&quot;&quot; Return a list of shape filled with num. Default value for num is 1 &quot;&quot;&quot; if isinstance(shape, tuple): x, y = shape return [[num]*y for _ in range(x)] else: x = shape return [num]*x . lst_nums(1, 1) . [1] . hund_1s = lst_nums((10, 10), 1) len(hund_1s), len(hund_1s[0]) . (10, 10) . hund_1s . [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]] . Here is a transpose function, which transposes a matrix. If you are not familiar with what it does, here is a wikipedia page with an animation. . def transpose (mat) -&gt; list: &quot;&quot;&quot; Transpose the matrix &quot;&quot;&quot; return [[m[i] for m in mat] for i in range(len(mat[0]))] . mat1 = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] . mat1 . [[1, 2, 3], [4, 5, 6], [7, 8, 9]] . transpose(mat1) . [[1, 4, 7], [2, 5, 8], [3, 6, 9]] . map_mat calls a fn (function) to a mat1 if there is only one matrix. If there are two matrices, it uses individual elements from both mat1 and mat2 as arguments for the fn. This is a long and complicated function, and I don&#39;t think I did a good job of writing it. It might be better to divide them by smaller functions, but I&#39;m not sure. How would you improve it? . def map_mat(fn, mat1, mat2=None) -&gt; list: &quot;&quot;&quot; If there is only one matrix, call the function on the matrix. If map_mat is called with two matrices, call the function with individual elements from mat1 and mat2 respectfully. This function can handle broadcasting when mat2 is a vector. &quot;&quot;&quot; if mat2 == None: return [list(map(fn, mat1[i])) for i in range(len(mat1))] mat = [] try: m1r,m1c = shape(mat1) except ValueError: m1r = shape(mat1)[0] m1c = 0 try: m2r,m2c = shape(mat2) except ValueError: m2r = shape(mat2)[0] m2c = 0 if m1c == m2c == 0: # Two 1D vectors return list(map(fn, mat1, mat2)) elif (m1r, m1c) == (m2r, m2c): # two matrixs with same sizes return [[fn(x,y) for x,y in zip(mat1[i], mat2[i])] for i in range(len(mat1))] elif m1c == m2r and m2c==0: # shape of (a, b), (b,) for i in range(m1r): mat.append([fn(x,y) for x,y in zip(mat1[i],mat2)]) return mat elif m1r == m2r and m2c == 0: # shape of (a, b), (a,) for i in range(m1r): mat.append([fn(m, mat2[i]) for m in mat1[i]]) return mat else: raise Exception(&quot;map_mat error&quot;) . hund_2s = lst_nums((10, 10), 2) . hund_3s = map_mat(lambda x, y: x+y, hund_1s, hund_2s) hund_3s . [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]] . map_mat(op.mul, hund_3s, hund_3s) . [[9, 9, 9, 9, 9, 9, 9, 9, 9, 9], [9, 9, 9, 9, 9, 9, 9, 9, 9, 9], [9, 9, 9, 9, 9, 9, 9, 9, 9, 9], [9, 9, 9, 9, 9, 9, 9, 9, 9, 9], [9, 9, 9, 9, 9, 9, 9, 9, 9, 9], [9, 9, 9, 9, 9, 9, 9, 9, 9, 9], [9, 9, 9, 9, 9, 9, 9, 9, 9, 9], [9, 9, 9, 9, 9, 9, 9, 9, 9, 9], [9, 9, 9, 9, 9, 9, 9, 9, 9, 9], [9, 9, 9, 9, 9, 9, 9, 9, 9, 9]] . map_mat(lambda x: x + 1, mat1) . [[2, 3, 4], [5, 6, 7], [8, 9, 10]] . Next, we have reshape function, which reshapes a matrix into new_shape. . def reshape(matrix, new_shape) -&gt; list: &quot;&quot;&quot; If matrix can be reshaped into new_shape, then return a new matrix with a respective shape. &quot;&quot;&quot; old_shape = shape(matrix) elem_nums = mul(old_shape) if old_shape == new_shape: return matrix elif not elem_nums == mul(new_shape): raise Exception(&quot;Wrong shape!&quot;) else: return shaping(flatten(matrix), new_shape, elem_nums) . def mul(lst: list) -&gt; int: &quot;&quot;&quot; Return a result of all numbers multiplied. Like sum, but multiplying. &quot;&quot;&quot; return reduce(op.mul, lst, 1) . def shaping(flat, new_shape, elem_nums): &quot;&quot;&quot; Actually shaping flat array into new shape. &quot;&quot;&quot; new_shape_len = len(new_shape) if new_shape_len == 1 or new_shape_len == 0: return result div = elem_nums // new_shape[0] # div = 50 result = [flat[(i * div):((i+1) * div)] for i in range(new_shape[0])] if new_shape_len == 2: return result else: return [shaping(result[i], new_shape[1:], div) for i in range(new_shape[0])] . def flatten(matrix): &quot;&quot;&quot; Flatten a matrix into a 1 dimensional list. &quot;&quot;&quot; result = [] for i in range(len(matrix)): if isinstance(matrix[i], list): result.extend(flatten(matrix[i])) else: result.append(matrix[i]) return result . Testing new tools . shape(reshape(hund_1s, (100, 1))), shape(reshape(hund_1s, (1, 100))) . ((100, 1), (1, 100)) . shape(reshape(hund_1s, (2, 5, 10))) . (2, 5, 10) . mat3 = [[[1, 2], [3, 4]], [[5, 6], [7, 8]]] mat3, shape(mat3) . ([[[1, 2], [3, 4]], [[5, 6], [7, 8]]], (2, 2, 2)) . shape(reshape(mat3, (4, 2))), reshape(mat3, (4, 2)) . ((4, 2), [[1, 2], [3, 4], [5, 6], [7, 8]]) . Collecting Data . With those utilities, we can get started on getting our hands dirty with deep learning. . First, we need data if we want to do some training. We are using MNIST dataset, which contains handwritten digits, from Yann Lecun website. The dataset has 60,000 training images and 10,000 testing images. When we look at amazing things computers were trained to do, such as self driving cars and speech recognition, there were actually a lot of data fed into them for training. Although we tend to only give credits to those who came up with state of the art models, nothing could have been possible without those who prepared for data. . !wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz !wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz !wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz !wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz . --2021-09-04 22:45:15-- http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz Resolving yann.lecun.com (yann.lecun.com)... 104.21.29.36, 172.67.171.76, 2606:4700:3034::6815:1d24, ... Connecting to yann.lecun.com (yann.lecun.com)|104.21.29.36|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 9912422 (9.5M) [application/x-gzip] Saving to: ‘train-images-idx3-ubyte.gz’ train-images-idx3-u 100%[===================&gt;] 9.45M --.-KB/s in 0.1s 2021-09-04 22:45:15 (88.0 MB/s) - ‘train-images-idx3-ubyte.gz’ saved [9912422/9912422] --2021-09-04 22:45:15-- http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz Resolving yann.lecun.com (yann.lecun.com)... 104.21.29.36, 172.67.171.76, 2606:4700:3034::6815:1d24, ... Connecting to yann.lecun.com (yann.lecun.com)|104.21.29.36|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 28881 (28K) [application/x-gzip] Saving to: ‘train-labels-idx1-ubyte.gz’ train-labels-idx1-u 100%[===================&gt;] 28.20K --.-KB/s in 0s 2021-09-04 22:45:15 (68.7 MB/s) - ‘train-labels-idx1-ubyte.gz’ saved [28881/28881] --2021-09-04 22:45:16-- http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz Resolving yann.lecun.com (yann.lecun.com)... 104.21.29.36, 172.67.171.76, 2606:4700:3034::6815:1d24, ... Connecting to yann.lecun.com (yann.lecun.com)|104.21.29.36|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 1648877 (1.6M) [application/x-gzip] Saving to: ‘t10k-images-idx3-ubyte.gz’ t10k-images-idx3-ub 100%[===================&gt;] 1.57M --.-KB/s in 0.06s 2021-09-04 22:45:16 (25.2 MB/s) - ‘t10k-images-idx3-ubyte.gz’ saved [1648877/1648877] --2021-09-04 22:45:16-- http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz Resolving yann.lecun.com (yann.lecun.com)... 104.21.29.36, 172.67.171.76, 2606:4700:3034::6815:1d24, ... Connecting to yann.lecun.com (yann.lecun.com)|104.21.29.36|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 4542 (4.4K) [application/x-gzip] Saving to: ‘t10k-labels-idx1-ubyte.gz’ t10k-labels-idx1-ub 100%[===================&gt;] 4.44K --.-KB/s in 0s 2021-09-04 22:45:16 (388 MB/s) - ‘t10k-labels-idx1-ubyte.gz’ saved [4542/4542] . !ls . data t10k-images-idx3-ubyte.gz train-images-idx3-ubyte.gz sample_data t10k-labels-idx1-ubyte.gz train-labels-idx1-ubyte.gz . Now, I am making a directory for all the data and putting data inside. . !mkdir data !mv train-images-idx3-ubyte.gz data/ !mv train-labels-idx1-ubyte.gz data/ !mv t10k-images-idx3-ubyte.gz data/ !mv t10k-labels-idx1-ubyte.gz data/ !ls data/ . mkdir: cannot create directory ‘data’: File exists t10k-images-idx3-ubyte.gz train-images-idx3-ubyte.gz t10k-labels-idx1-ubyte.gz train-labels-idx1-ubyte.gz . Now, we have files we need. With py_mnist_images and py_mnist_labels, we convert these files into lists of images. I got those functions from here, which originally returned numpy arrays, but I changed them to return lists. After calling those functions, we call reshape function to make them shapes of images, which are 28 by 28 pixels. . def py_mnist_images(fname:str, pct=1) -&gt; list: &quot;&quot;&quot; Convert zip files into lists of images. Only returning pct percent of data. &quot;&quot;&quot; with gzip.open(&#39;data/&#39;+fname, &#39;r&#39;) as f: # first 4 bytes is a magic number magic_number = int.from_bytes(f.read(4), &#39;big&#39;) # second 4 bytes is the number of images image_count = int.from_bytes(f.read(4), &#39;big&#39;) # image_count = int(image_count * percent) # third 4 bytes is the row count row_count = int.from_bytes(f.read(4), &#39;big&#39;) # fourth 4 bytes is the column count column_count = int.from_bytes(f.read(4), &#39;big&#39;) # rest is the image pixel data, each pixel is stored as an unsigned byte # pixel values are 0 to 255 image_data = f.read() images = reshape(list(image_data), (image_count, column_count, row_count)) return images[:int(image_count * pct)] # return reshape(images, (image_count, column_count, row_count)) def py_mnist_labels(fname:str, pct=1) -&gt; list: &quot;&quot;&quot; Convert zip files into lists of labels. Only returning pct percent of data. &quot;&quot;&quot; with gzip.open(&#39;data/&#39;+fname, &#39;r&#39;) as f: # first 4 bytes is a magic number magic_number = int.from_bytes(f.read(4), &#39;big&#39;) # second 4 bytes is the number of labels label_count = int.from_bytes(f.read(4), &#39;big&#39;) # rest is the label data, each label is stored as unsigned byte # label values are 0 to 9 label_data = f.read() labels = list(label_data) return labels[:int(label_count * pct)] . With py_mnist_images, we get lists of images. We call these matrices. When an array has 1 dimension, it is a vector, and an array 2 or more dimensions is called matrix. . Let&#39;s use only 1% of the data because python is slow. . train_imgs = py_mnist_images(&#39;train-images-idx3-ubyte.gz&#39;, pct=0.01) train_labels = py_mnist_labels(&#39;train-labels-idx1-ubyte.gz&#39;, pct=0.01) test_imgs = py_mnist_images(&#39;t10k-images-idx3-ubyte.gz&#39;, pct=0.01) test_labels = py_mnist_labels(&#39;t10k-labels-idx1-ubyte.gz&#39;, pct=0.01) . Let&#39;s take a look at those data before we move on. We want to make sure we are working with correct data. Using plt.imshow, we can take a look at each image. . type(train_imgs), type(train_imgs[0][0][0]) . (list, int) . shape(train_imgs), shape(train_labels), shape(test_imgs), shape(test_labels) . ((600, 28, 28), (600,), (100, 28, 28), (100,)) . Here are pictures with labels. . plt.imshow(train_imgs[0], cmap=&#39;gray&#39;); train_labels[0] . 5 . plt.imshow(train_imgs[1], cmap=&#39;gray&#39;); train_labels[1] . 0 . plt.imshow(train_imgs[2], cmap=&#39;gray&#39;); train_labels[2] . 4 . Now that we have some tools to work with, we can prepare our data for training. First, we will reshape our data. We are combining x and y axis into a vector (1-dimensional array) so that one array equals to one image. Then, we normalize our data by dividing them by 255 because the highest value is 255. . train_imgs = reshape(train_imgs, (600, 28 * 28)) test_imgs = reshape(test_imgs, (100, 28 * 28)) shape(train_imgs), shape(test_imgs) . ((600, 784), (100, 784)) . train_imgs = map_mat(lambda x: x / 255, train_imgs) test_imgs = map_mat(lambda x: x / 255, test_imgs) . Initializing Weights and Biases . Now that we have data, we need weights and biases. We can just think of these as matrices of random numbers. By training models, we are trying to change these random numbers into right ones that will give us good results. . def lst_random(shape, init_parms=False): &quot;&quot;&quot; return a list of randoms and if init_parms is True, initialize parameters using Kaiming init. &quot;&quot;&quot; x, y = shape res = lst_nums(shape, 0) for i in range(x): for j in range(y): res[i][j] = random.normalvariate(0,1) if init_parms: res[i][j] *= math.sqrt(2/x) return res . rand_mat = lst_random((10,10)) shape(rand_mat) . (10, 10) . With Kaiming initialization, we can train deeper models. . sample = lst_random((200, 100), True) # x = map_mat(lambda x: x*0.1, x) # statistics.stdev(x[0]) . Checking whether the initialization works. Standard deviation should equal to sqrt(2/n_in), and mean should be 0. And this works. With this initialization, we can train deeper layers. For more information, paper is here. . def check_dist(x): for i in range(len(x)//10): print(statistics.stdev(x[i]), statistics.mean(x[i])) . math.sqrt(2/200) . 0.1 . check_dist(sample) . 0.09403171521976275 0.013622055097298417 0.11022747597801236 0.004275158318235466 0.10391848009119782 -0.01736304265045632 0.10158040902814837 -0.02140397506068278 0.09882006911891293 -0.0053818314803667595 0.10310174401159848 0.000929601684799433 0.10590896519472498 -0.002986448136461439 0.10860384191536261 -0.0019467197654269364 0.10334640758604192 0.00022377121525137602 0.10250798204880954 -0.005277651317013858 0.09689419991073889 -0.011304377462247831 0.10161001000236593 0.0012921971242199144 0.10496614902299435 0.01890044117944085 0.10825130611808448 0.0014377722556012744 0.09529078477492108 -0.012941433333789797 0.09452227869299638 0.0011131585828455986 0.10649544360871815 -0.014153836025424677 0.10728331890142034 0.011419162266351656 0.09875726811080487 -0.008044575164524132 0.10548583913595076 0.001835162672406242 . Matrix multiplication . Now that our data is ready, it is time to look at matrix multiplication, which is the most frequently used operation in deep learning. . Here is my implementation of matrix multiplication. There are other ways to do it, but I found this to be the fastest so far. . m1 = [[1, 2], [3, 4]] m2 = [[5, 4], [3, 2]] . def py_matmul(a, b): &quot;&quot;&quot; Matrix multiplication &quot;&quot;&quot; ar,ac = len(a),len(a[0]) br,bc = len(b),len(b[0]) assert ac == br, f&#39;Size of ar ({ac}) does not match br ({br}).&#39; c = lst_nums((ar, bc), 0) t = transpose(b) for i in range(ar): c[i] = [sum(map(op.mul, a[i], t[j])) for j in range(bc)] return c . py_matmul(m1, m2) . [[11, 8], [27, 20]] . Model . It is time to make a model to train. Let&#39;s briefly look at what they do. Each function has a forward pass and a backward pass. Backward pass finds gradients and allows us to use stochastic gradient descent (SGD). Stochastic gradient descent is how we can train our model automatically and get our random weights and biases closer to right numbers that will suit to our needs. . Relu turns negative number into zeros. . class Relu(): def forward(self, x): self.old_x = x.copy() res = map_mat(lambda y: 0 if y &lt; 0 else y, x) return res def backward(self, grad): res = map_mat(lambda x, g: g if x &gt; 0 else 0, self.old_x, grad) return res . Softmax is used when there are many categories to predict. Our data has to predict ten categories, from zero to ten. . class Softmax(): def forward(self, inp): mat = map_mat(math.exp, inp) self.old_y = [] for i in range(len(mat)): s = sum(mat[i]) self.old_y.append([x/s for x in mat[i]]) return self.old_y def backward(self, grad): res = map_mat(op.mul, self.old_y, grad) res = [sum(res[i]) for i in range(len(self.old_y))] # shape is (64,) return map_mat(op.mul, self.old_y, map_mat(op.sub, grad, res)) . Cross entropy loss measures how well our model is doing, and from that, our model can get our weights and biases closer to better ones that will give us better predictions. . class CrossEntropy(): def forward(self, inp, targ): mat = map_mat(lambda x: x if x&gt;1e-8 else 1e-8, inp) self.old_x = mat.copy() self.old_y = targ res = [] for i in range(len(mat)): for j in range(len(targ[0])): if targ[i][j] == 1: res.append(-math.log(mat[i][j])) return res def backward(self): mat = map_mat(lambda x: x if x&gt;1e-8 else 1e-8, self.old_x) res = lst_nums(shape(mat), num=0.) for i in range(len(mat)): for j in range(len(self.old_y[0])): if self.old_y[i][j] == 1: res[i][j] = (-1/(mat[i][j])) return res . Linear is just matrix multiplication of our input, which is a matrix of images, and weights, which we initialize with random numbers. After a matrix multiplication, there is an addition of the result and bias, which are initialized to zeros. . class Linear(): def __init__(self, n_in, n_out): self.weights = lst_random((n_in, n_out), True) self.biases = lst_nums((n_out), num=0) def forward(self, inp): self.old_x = inp.copy() return map_mat(lambda x, y: x + y, py_matmul(inp, self.weights), self.biases) def backward(self, grad): self.grad_b = mean_0(grad) self.grad_w = py_matmul(transpose(self.old_x), grad) out = py_matmul(grad, transpose(self.weights)) return out . def mean_0 (matrix): &quot;Find a mean in matrix over 0 axis&quot; return [statistics.mean([m[i] for m in matrix]) for i in range(len(matrix[0]))] . Here is our model. It has forward and backward, loss, and make_preds. This is how we combine our functions, or layers, for training. . class Model(): def __init__(self, layers, cost): self.layers = layers self.cost = cost def forward(self,x): for layer in self.layers: x = layer.forward(x) return x def make_preds(self, x): outputs = self.forward(x) # (64, 10) preds = [outputs[i].index(max(outputs[i])) for i in range(len(outputs))] return preds def loss(self,x,y): return self.cost.forward(self.forward(x),y) def backward(self): grad = self.cost.backward() for i in range(len(self.layers)-1,-1,-1): grad = self.layers[i].backward(grad) . Here, by calling load_minibatches, we turn our training images and labels into little batches. This way, we can update our weights and biases more efficiently. If we try to update with the whole dataset, it is very slow. If we just use one image at a time, our model can get too biased, rather than being generalized over different kind of input. This returns a dataset, which is a set of images and labels combined together. . def load_minibatches(trn, targets, bs=64): &quot;&quot;&quot; Turn our inputs and labels into a dataset containing minibatches &quot;&quot;&quot; data = [] for i in range((len(trn) // bs) - 1): targs = lst_nums((bs, 10), 0) targets_mb = targets[(i*bs) : ((i+1)*bs)] for z in range(bs): targs[z][targets_mb[z]] = 1. data.append((trn[:bs],targs)) return data . dataset = load_minibatches(train_imgs, train_labels) shape(dataset) . (8,) . This is our train function. It trains the model with training data with learning rate for epochs, and uses testset for validation. Learning rate is used to determine how fast we update our weights and biases. Epoch determines how many times the model sees the whole data. Here, train also calculates accuracy by making predictions from testset. This is important because we can see how well our model performs on data that it has not seen yet. After training for a while, even if our training loss can be reduced a lot, it could possibly have a high validation loss with testset. After all, what use does our model have if it only distinguish numbers it has seen before but not the new numbers? . def train(model,lr,nb_epoch,data, testset): &quot;&quot;&quot; Train our model &quot;&quot;&quot; for epoch in range(nb_epoch): running_loss = 0. num_inputs = 0 for mini_batch in data: corrects = 0 inputs,targets = mini_batch test_inp, test_targs = testset num_inputs += len(inputs) #Forward pass + compute loss preds = model.make_preds(test_inp) for i in range(len(preds)): if test_targs[i] == preds[i]: corrects += 1 # print(corrects) running_loss += sum(model.loss(inputs,targets)) #Back propagation model.backward() #Update of the parameters for layer in model.layers: if type(layer) == Linear: weight_diff = [list(map(lambda x: x * lr, layer.grad_w[i])) for i in range(len(layer.grad_w))] layer.weights = map_mat(op.sub, layer.weights, weight_diff) bias_diff = list(map(lambda x: x * lr, layer.grad_b)) layer.biases = map_mat(op.sub, layer.biases, bias_diff) # print(f&#39;loss = {running_loss/num_inputs}, Accuracy = {corrects*100 / len(preds)}&#39;) print(f&#39;Epoch {epoch+1}/{nb_epoch}: loss = {running_loss/num_inputs}, Accuracy = {corrects*100 / len(preds)}&#39;) . Here is our neural net with different layers. By using Model, we can easily make new model and try out how they perform. . net = Model([Linear(784,60), Relu(), Linear(60,10), Softmax()], CrossEntropy()) . Now we finally train! . train(net, 0.01, 3, dataset, (test_imgs, test_labels)) . Epoch 1/3: loss = 2.378668682344605, Accuracy = 32.0 Epoch 2/3: loss = 2.244675878898528, Accuracy = 33.0 Epoch 3/3: loss = 2.2046788634640855, Accuracy = 35.0 . We are done with training. How can we do better? .",
            "url": "https://meinkappa.github.io/blog/2021/09/04/My-First-Neural-Net.html",
            "relUrl": "/2021/09/04/My-First-Neural-Net.html",
            "date": " • Sep 4, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "First markdown page",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Strikethrough . Strike me hard!! . Taskings to complete . Wake up. | Try to stay awake. | Try harder. | Give it a little more. | Maybe a tiny bit more. | Take a little break. | . Footnotes . This is the footnote. &#8617; . |",
            "url": "https://meinkappa.github.io/blog/markdown/2021/08/01/test-post.html",
            "relUrl": "/markdown/2021/08/01/test-post.html",
            "date": " • Aug 1, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://meinkappa.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://meinkappa.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://meinkappa.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://meinkappa.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}