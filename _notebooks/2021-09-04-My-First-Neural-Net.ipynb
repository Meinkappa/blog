{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist_Python_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rrtRAkL3p_Y"
      },
      "source": [
        "# Deep learning with standard Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeOPKvmxyJG9"
      },
      "source": [
        "Here, we will be traing a deep learning model with only Python. The only 3rd party libary I will be using is matplotlib to show images. This is my first neural net I wrote. If you see some kind of error, please let me know through this email: shipalnomoo at gmail.com. This is a quick hands on exercise. Rather than focusing on theory, this is more hands on to feel what it is to train a model. we will explore what it means to train a model using MNIST handwritten dataset. When I was reading a [blog post](https://sgugger.github.io/a-simple-neural-net-in-numpy.html#a-simple-neural-net-in-numpy) from Sylvain Gugger called, \"A simple neural net in numpy,\" I found it interesting and wanted to try to write my version in standard Python. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9b7gBrPnZ6X"
      },
      "source": [
        "There are many libraries used for deep learning, such as Tensorflow and Keras, Pytorch, Scikit-Learn, numpy, and others. However, in order to understand basic concept of deep learning, we do no need to use any of these tools. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd2OK2EYuBuS"
      },
      "source": [
        "Here are Python libraries I will be using. Other than matplotlib, all libraries are here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUdSF1LI_ihk"
      },
      "source": [
        "import gzip                             # Converting zip into python objects\n",
        "import matplotlib.pyplot as plt         # Library for showing images\n",
        "import random                           # Initializing random weights\n",
        "import statistics                       # Getting mean or stdev\n",
        "import math                             # Exponential function\n",
        "import operator as op                   # just algebraic operators such as +, -, *, /\n",
        "import time                             # Timing for performance\n",
        "from functools import reduce"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeEFHBXRyolB"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVqIin2ocZSm"
      },
      "source": [
        "This section can be skipped as you can understand how deep learning works without understanding how these utilities work. You can consider these as built-in functions or machine language blobs. Simply fold the heading and run it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL_G6tlCyu64"
      },
      "source": [
        "If you decided to dig into lower level of deep learning, let's begin. Because we are only using python lists, we need to build utilities or tools we need in order to train our model. With other fancy libraries, these are built-in. However, because we are building up from scratch, we start with those basic utilities that we will use later on. How these are implemented specifically are not important at all for our purpose of understanding how deep learning works. As long as you get the general idea of what these functions do, that is good enough. However, please do not just run those cells without thinking about what they will return in advance if you want to understand more. Give yourself couple seconds to think and come up with output in your head. This will change your level of understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6njxdMPvv7iW"
      },
      "source": [
        "With those low level functions, we will build up abstraction layers. First, I start with `shape`, which returns a tuple of shape of a matrix or a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVNEQEJNyIrB"
      },
      "source": [
        "def shape(matrix) -> tuple:\n",
        "    \"\"\" \n",
        "    Get a shape of a matrix \n",
        "    \"\"\"\n",
        "    def loop(mat, result):\n",
        "        if not isinstance(mat, list):\n",
        "            return result\n",
        "        else:\n",
        "            return loop(mat[0], result + (len(mat),))\n",
        "    return loop(matrix, tuple())"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjbCv6TPW8eS",
        "outputId": "ec599a40-d23d-4bfe-f737-39c8abf8e846"
      },
      "source": [
        "shape([1, 2])"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxEcAKVBXTAF",
        "outputId": "3199558e-8db4-4f42-e3d9-1d317bf83ca1"
      },
      "source": [
        "shape([[1, 2, 3],\n",
        "       [4, 5, 6]])"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCoJtPW9XVex",
        "outputId": "97d2ebf9-968e-4006-d31b-5915d3b8f862"
      },
      "source": [
        "shape([[[1, 2],\n",
        "        [3, 4]]])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHT-j-Qi4tDu"
      },
      "source": [
        "It would be better if we can make matrices easier instead of making them by hand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzSsTWH10SPj"
      },
      "source": [
        "def lst_nums(shape:tuple, num:int=1) -> list:\n",
        "    \"\"\" \n",
        "    Return a list of shape filled with num. \n",
        "    Default value for num is 1 \n",
        "    \"\"\"\n",
        "    if isinstance(shape, tuple):\n",
        "        x, y = shape\n",
        "        return [[num]*y for _ in range(x)]\n",
        "    else:\n",
        "        x = shape\n",
        "        return [num]*x"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t35ZwPwdbcD4",
        "outputId": "73972cfe-19a2-489b-f738-6e9648c4db2d"
      },
      "source": [
        "lst_nums(1, 1)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kloNTeasf1pF",
        "outputId": "a999a16f-125c-4108-8b6b-67521d4435fb"
      },
      "source": [
        "hund_1s = lst_nums((10, 10), 1)\n",
        "len(hund_1s), len(hund_1s[0])"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms10jgtPmQdR",
        "outputId": "21add7c6-4c46-48bc-f5d8-cfea6f02ad6c"
      },
      "source": [
        "hund_1s"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3qfotpLehFN"
      },
      "source": [
        "Here is a transpose function, which transposes a matrix. If you are not familiar with what it does, here is a [wikipedia](https://en.wikipedia.org/wiki/Transpose) page with an animation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QwjE94JptOr"
      },
      "source": [
        "def transpose (mat) -> list:\n",
        "    \"\"\"\n",
        "    Transpose the matrix\n",
        "    \"\"\"\n",
        "    return [[m[i] for m in mat] for i in range(len(mat[0]))]"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9gZUXtWhSIh"
      },
      "source": [
        "mat1 = [[1, 2, 3],\n",
        "        [4, 5, 6],\n",
        "        [7, 8, 9]]"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0HEGrc2g2JJ",
        "outputId": "2a241a64-0915-4d47-86bd-e6d415b4b682"
      },
      "source": [
        "mat1"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaKmQ0pShasm",
        "outputId": "85bdb366-6e20-4eb9-d2a0-4365622b1597"
      },
      "source": [
        "transpose(mat1)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 4, 7], [2, 5, 8], [3, 6, 9]]"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG3H9g_Xmsrq"
      },
      "source": [
        "`map_mat` calls a fn (function) to a mat1 if there is only one matrix. If there are two matrices, it uses individual elements from both mat1 and mat2 as arguments for the fn. This is a long and complicated function, and I don't think I did a good job of writing it. It might be better to divide them by smaller functions, but I'm not sure. How would you improve it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2K15xPgT2nZ"
      },
      "source": [
        "def map_mat(fn, mat1, mat2=None) -> list:\n",
        "    \"\"\" \n",
        "    If there is only one matrix, call the function on the matrix.\n",
        "    If map_mat is called with two matrices, call the function with \n",
        "    individual elements from mat1 and mat2 respectfully. \n",
        "    This function can handle broadcasting when mat2 is a vector. \n",
        "    \"\"\"\n",
        "    if mat2 == None:\n",
        "        return [list(map(fn, mat1[i])) for i in range(len(mat1))]\n",
        "    mat = []\n",
        "    try: \n",
        "        m1r,m1c = shape(mat1)\n",
        "    except ValueError: \n",
        "        m1r = shape(mat1)[0]\n",
        "        m1c = 0\n",
        "    try: \n",
        "        m2r,m2c = shape(mat2)\n",
        "    except ValueError: \n",
        "        m2r = shape(mat2)[0]\n",
        "        m2c = 0\n",
        "    if m1c == m2c == 0:                     # Two 1D vectors\n",
        "        return list(map(fn, mat1, mat2))\n",
        "    elif (m1r, m1c) == (m2r, m2c):          # two matrixs with same sizes\n",
        "        return [[fn(x,y) for x,y in zip(mat1[i], mat2[i])] for i in range(len(mat1))]\n",
        "    elif m1c == m2r and m2c==0:             # shape of (a, b), (b,)\n",
        "        for i in range(m1r):\n",
        "            mat.append([fn(x,y) for x,y in zip(mat1[i],mat2)])\n",
        "        return mat\n",
        "    elif m1r == m2r and m2c == 0:           # shape of (a, b), (a,)\n",
        "        for i in range(m1r):\n",
        "            mat.append([fn(m, mat2[i]) for m in mat1[i]])\n",
        "        return mat\n",
        "    else:\n",
        "        raise Exception(\"map_mat error\")"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOmejvQ7l_XD"
      },
      "source": [
        "hund_2s = lst_nums((10, 10), 2)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YD6Q-iSnwEh",
        "outputId": "435dbe9b-821a-4541-d7a6-7c8232fc664d"
      },
      "source": [
        "hund_3s = map_mat(lambda x, y: x+y, hund_1s, hund_2s)\n",
        "hund_3s"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
              " [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
              " [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
              " [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
              " [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
              " [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
              " [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
              " [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
              " [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
              " [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM-3W_xOqeU1",
        "outputId": "1eab3718-440c-41f4-cbdc-848f366ec23e"
      },
      "source": [
        "map_mat(op.mul, hund_3s, hund_3s)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
              " [9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
              " [9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
              " [9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
              " [9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
              " [9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
              " [9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
              " [9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
              " [9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
              " [9, 9, 9, 9, 9, 9, 9, 9, 9, 9]]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gTuQa-SYfEx",
        "outputId": "c1246c37-0a9e-452e-bf03-cd73d6e50fe3"
      },
      "source": [
        "map_mat(lambda x: x + 1, mat1)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3, 4], [5, 6, 7], [8, 9, 10]]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIxYBmPVxZoG"
      },
      "source": [
        "Next, we have `reshape` function, which reshapes a matrix into new_shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l58QgfFcy-cH"
      },
      "source": [
        "def reshape(matrix, new_shape) -> list:\n",
        "    \"\"\" \n",
        "    If matrix can be reshaped into new_shape, then\n",
        "    return a new matrix with a respective shape. \n",
        "    \"\"\"\n",
        "    old_shape = shape(matrix)\n",
        "    elem_nums = mul(old_shape)\n",
        "    if old_shape == new_shape:\n",
        "        return matrix\n",
        "    elif not elem_nums == mul(new_shape):\n",
        "        raise Exception(\"Wrong shape!\")\n",
        "    else:\n",
        "        return shaping(flatten(matrix), new_shape, elem_nums)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIS4K3984lDW"
      },
      "source": [
        "def mul(lst: list) -> int:\n",
        "    \"\"\" \n",
        "    Return a result of all numbers multiplied.\n",
        "    Like sum, but multiplying. \n",
        "    \"\"\"\n",
        "    return reduce(op.mul, lst, 1)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8EuSwfcXjZX"
      },
      "source": [
        "def shaping(flat, new_shape, elem_nums):\n",
        "    \"\"\" \n",
        "    Actually shaping flat array into new shape. \n",
        "    \"\"\"\n",
        "    new_shape_len = len(new_shape)\n",
        "    if new_shape_len == 1 or new_shape_len == 0:\n",
        "        return result\n",
        "    div = elem_nums // new_shape[0] # div = 50\n",
        "    result = [flat[(i * div):((i+1) * div)] for i in range(new_shape[0])]\n",
        "    if new_shape_len == 2:\n",
        "        return result\n",
        "    else:\n",
        "        return [shaping(result[i], new_shape[1:], div) for i in range(new_shape[0])]"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viHxPFfUp5L7"
      },
      "source": [
        "def flatten(matrix):\n",
        "    \"\"\" \n",
        "    Flatten a matrix into a 1 dimensional list. \n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for i in range(len(matrix)):\n",
        "        if isinstance(matrix[i], list):\n",
        "            result.extend(flatten(matrix[i]))\n",
        "        else:\n",
        "            result.append(matrix[i])\n",
        "    return result"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5zbAsj8uM63"
      },
      "source": [
        "Testing new tools "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXhBXyVc4dWh",
        "outputId": "6860d739-1005-4967-8fa6-caf8cf2bf641"
      },
      "source": [
        "# Reshape works with shape function.\n",
        "shape(reshape(hund_1s, (100, 1))), shape(reshape(hund_1s, (1, 100)))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 1), (1, 100))"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30Xr8J8VHEi6",
        "outputId": "3fe54a17-b5bc-4a78-e9ea-ce20a534e68a"
      },
      "source": [
        "shape(reshape(hund_1s, (2, 5, 10)))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 5, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEp1bYyruL7U",
        "outputId": "9c5d7ad3-5ed1-47c7-ea0f-cf1dc39fdff3"
      },
      "source": [
        "mat3 = [[[1, 2],\n",
        "         [3, 4]],\n",
        "        [[5, 6],\n",
        "         [7, 8]]]\n",
        "mat3, shape(mat3)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[[1, 2], [3, 4]], [[5, 6], [7, 8]]], (2, 2, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-SWDclAu0fa",
        "outputId": "51e4b7b1-9a2b-42db-fa54-0cd18892199c"
      },
      "source": [
        "shape(reshape(mat3, (4, 2))), reshape(mat3, (4, 2))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4, 2), [[1, 2], [3, 4], [5, 6], [7, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keM-2-8TqMf1"
      },
      "source": [
        "## Collecting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jb_pxFIrbwy"
      },
      "source": [
        "With those utilities, we can get started on getting our hands dirty with deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43tZbVtO5zbH"
      },
      "source": [
        "First, we need data if we want to do some training. We are using [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database), which contains handwritten digits, from Yann Lecun website. The dataset has 60,000 training images and 10,000 testing images. When we look at amazing things computers were trained to do, such as self driving cars and speech recognition, there were actually a lot of data fed into them for training. Although we tend to only give credits to those who came up with state of the art models, nothing could have been possible without those who prepared for data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYWKuIgIwl3C",
        "outputId": "be6d8083-620d-41ca-9b9f-dbd0d5ec4056"
      },
      "source": [
        "!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
        "!wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-04 22:45:15--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 104.21.29.36, 172.67.171.76, 2606:4700:3034::6815:1d24, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|104.21.29.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9912422 (9.5M) [application/x-gzip]\n",
            "Saving to: ‘train-images-idx3-ubyte.gz’\n",
            "\n",
            "\r          train-ima   0%[                    ]       0  --.-KB/s               \rtrain-images-idx3-u 100%[===================>]   9.45M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-09-04 22:45:15 (88.0 MB/s) - ‘train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n",
            "\n",
            "--2021-09-04 22:45:15--  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 104.21.29.36, 172.67.171.76, 2606:4700:3034::6815:1d24, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|104.21.29.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28881 (28K) [application/x-gzip]\n",
            "Saving to: ‘train-labels-idx1-ubyte.gz’\n",
            "\n",
            "train-labels-idx1-u 100%[===================>]  28.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-04 22:45:15 (68.7 MB/s) - ‘train-labels-idx1-ubyte.gz’ saved [28881/28881]\n",
            "\n",
            "--2021-09-04 22:45:16--  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 104.21.29.36, 172.67.171.76, 2606:4700:3034::6815:1d24, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|104.21.29.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1648877 (1.6M) [application/x-gzip]\n",
            "Saving to: ‘t10k-images-idx3-ubyte.gz’\n",
            "\n",
            "t10k-images-idx3-ub 100%[===================>]   1.57M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-09-04 22:45:16 (25.2 MB/s) - ‘t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n",
            "\n",
            "--2021-09-04 22:45:16--  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 104.21.29.36, 172.67.171.76, 2606:4700:3034::6815:1d24, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|104.21.29.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4542 (4.4K) [application/x-gzip]\n",
            "Saving to: ‘t10k-labels-idx1-ubyte.gz’\n",
            "\n",
            "t10k-labels-idx1-ub 100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-04 22:45:16 (388 MB/s) - ‘t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Oq__BUhPsIe",
        "outputId": "0c5ee7ec-96b0-4038-e735-dc6764aafd03"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t     t10k-images-idx3-ubyte.gz\ttrain-images-idx3-ubyte.gz\n",
            "sample_data  t10k-labels-idx1-ubyte.gz\ttrain-labels-idx1-ubyte.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekZbb9IDCMEn"
      },
      "source": [
        "Now, I am making a directory for all the data and putting data inside."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx-n4pPN0IeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8caf8684-5fa8-4ab3-c6e0-ab486b7a3beb"
      },
      "source": [
        "# Todo: Change the code into using python pathlib library \n",
        "!mkdir data\n",
        "!mv train-images-idx3-ubyte.gz data/\n",
        "!mv train-labels-idx1-ubyte.gz data/\n",
        "!mv t10k-images-idx3-ubyte.gz data/\n",
        "!mv t10k-labels-idx1-ubyte.gz data/\n",
        "!ls data/"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "t10k-images-idx3-ubyte.gz  train-images-idx3-ubyte.gz\n",
            "t10k-labels-idx1-ubyte.gz  train-labels-idx1-ubyte.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ21AzC799sJ"
      },
      "source": [
        "Now, we have files we need. With `py_mnist_images` and `py_mnist_labels`, we convert these files into lists of images. I got those functions from [here](https://stackoverflow.com/questions/40427435/extract-images-from-idx3-ubyte-file-or-gzip-via-python), which originally returned numpy arrays, but I changed them to return lists. After calling those functions, we call `reshape` function to make them shapes of images, which are 28 by 28 pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1IW-pImYwOz"
      },
      "source": [
        "def py_mnist_images(fname:str, pct=1) -> list:\n",
        "    \"\"\" \n",
        "    Convert zip files into lists of images. \n",
        "    Only returning pct percent of data.     \n",
        "    \"\"\"\n",
        "    with gzip.open('data/'+fname, 'r') as f:\n",
        "        # first 4 bytes is a magic number\n",
        "        magic_number = int.from_bytes(f.read(4), 'big')\n",
        "        # second 4 bytes is the number of images\n",
        "        image_count = int.from_bytes(f.read(4), 'big')\n",
        "        # image_count = int(image_count * percent)\n",
        "        # third 4 bytes is the row count\n",
        "        row_count = int.from_bytes(f.read(4), 'big')\n",
        "        # fourth 4 bytes is the column count\n",
        "        column_count = int.from_bytes(f.read(4), 'big')\n",
        "        # rest is the image pixel data, each pixel is stored as an unsigned byte\n",
        "        # pixel values are 0 to 255\n",
        "        image_data = f.read()\n",
        "        images = reshape(list(image_data), (image_count, column_count, row_count))\n",
        "        return images[:int(image_count * pct)]\n",
        "        # return reshape(images, (image_count, column_count, row_count))\n",
        "\n",
        "def py_mnist_labels(fname:str, pct=1) -> list:\n",
        "    \"\"\" \n",
        "    Convert zip files into lists of labels. \n",
        "    Only returning pct percent of data.     \n",
        "    \"\"\"\n",
        "    with gzip.open('data/'+fname, 'r') as f:\n",
        "        # first 4 bytes is a magic number\n",
        "        magic_number = int.from_bytes(f.read(4), 'big')\n",
        "        # second 4 bytes is the number of labels\n",
        "        label_count = int.from_bytes(f.read(4), 'big')\n",
        "        # rest is the label data, each label is stored as unsigned byte\n",
        "        # label values are 0 to 9\n",
        "        label_data = f.read()\n",
        "        labels = list(label_data)\n",
        "        return labels[:int(label_count * pct)]"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kvsF_9is-GB"
      },
      "source": [
        "With `py_mnist_images`, we get lists of images. We call these matrices. When an array has 1 dimension, it is a vector, and an array 2 or more dimensions is called matrix. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoJuR7G5xa6a"
      },
      "source": [
        "Let's use only 1% of the data because python is slow. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C4IzaPy_gLT"
      },
      "source": [
        "train_imgs = py_mnist_images('train-images-idx3-ubyte.gz', pct=0.01)\n",
        "train_labels = py_mnist_labels('train-labels-idx1-ubyte.gz', pct=0.01)\n",
        "test_imgs = py_mnist_images('t10k-images-idx3-ubyte.gz', pct=0.01)\n",
        "test_labels = py_mnist_labels('t10k-labels-idx1-ubyte.gz', pct=0.01)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd4bJLkhSyt_"
      },
      "source": [
        "Let's take a look at those data before we move on. We want to make sure we are working with correct data. Using `plt.imshow`, we can take a look at each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdthMy4xDun0",
        "outputId": "aab563b9-57e3-42fb-e8d4-c4766776594f"
      },
      "source": [
        "type(train_imgs), type(train_imgs[0][0][0])"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, int)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaVAU7_KsXo1",
        "outputId": "8f30e7a2-6b4a-407b-881c-bd5c8c71007b"
      },
      "source": [
        "shape(train_imgs), shape(train_labels), shape(test_imgs), shape(test_labels)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((600, 28, 28), (600,), (100, 28, 28), (100,))"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bveQs7JnzVa6"
      },
      "source": [
        "Here are pictures with labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "Zf0y1_Lcsn0g",
        "outputId": "94041aed-214b-4918-92a3-d2781c3d8cc7"
      },
      "source": [
        "plt.imshow(train_imgs[0], cmap='gray'); train_labels[0]"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 142
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "43DJFysBzPpr",
        "outputId": "a727a9a3-3dc9-4b4a-d9ad-f15ee70ca713"
      },
      "source": [
        "plt.imshow(train_imgs[1], cmap='gray'); train_labels[1]"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 143
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "kJdkJ99TzSV5",
        "outputId": "03246e6e-8546-4fa3-d114-39dd1ff83f40"
      },
      "source": [
        "plt.imshow(train_imgs[2], cmap='gray'); train_labels[2]"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 144
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNP5aO5lvH6D"
      },
      "source": [
        "Now that we have some tools to work with, we can prepare our data for training. First, we will reshape our data. We are combining x and y axis into a vector (1-dimensional array) so that one array equals to one image. Then, we normalize our data by dividing them by 255 because the highest value is 255. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H81tDb695ORu",
        "outputId": "2b0ac4c5-40c0-4aa5-a9f3-86827bd53cf9"
      },
      "source": [
        "train_imgs = reshape(train_imgs, (600, 28 * 28))\n",
        "test_imgs = reshape(test_imgs, (100, 28 * 28))\n",
        "shape(train_imgs), shape(test_imgs)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((600, 784), (100, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DNkZ7opV0sm"
      },
      "source": [
        "train_imgs = map_mat(lambda x: x / 255, train_imgs)\n",
        "test_imgs = map_mat(lambda x: x / 255, test_imgs)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWRMRkvsxvj3"
      },
      "source": [
        "## Initializing Weights and Biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuYxwTYE9FPq"
      },
      "source": [
        "Now that we have data, we need weights and biases. We can just think of these as matrices of random numbers. By training models, we are trying to change these random numbers into right ones that will give us good results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vx-dBJ12VlH"
      },
      "source": [
        "def lst_random(shape, init_parms=False):\n",
        "    \"\"\"\n",
        "    return a list of randoms and if init_parms is True, \n",
        "    initialize parameters using Kaiming init.\n",
        "    \"\"\"\n",
        "    x, y = shape\n",
        "    res = lst_nums(shape, 0)\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            res[i][j] = random.normalvariate(0,1)\n",
        "            if init_parms: res[i][j] *= math.sqrt(2/x)\n",
        "    return res"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8XSCmBjpKqj",
        "outputId": "ad7172c6-3ea2-46f1-d386-6a071003295d"
      },
      "source": [
        "rand_mat = lst_random((10,10))\n",
        "shape(rand_mat)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGDAEjw3_JI8"
      },
      "source": [
        "With Kaiming initialization, we can train deeper models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztld9OD3hzPB"
      },
      "source": [
        "sample = lst_random((200, 100), True)\n",
        "# x = map_mat(lambda x: x*0.1, x)\n",
        "# statistics.stdev(x[0])"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQsr5tku--ge"
      },
      "source": [
        "Checking whether the initialization works. Standard deviation should equal to sqrt(2/n_in), and mean should be 0. And this works. With this initialization, we can train deeper layers. For more information, paper is [here](https://arxiv.org/abs/1502.01852)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvVUj1eaIuhu"
      },
      "source": [
        "def check_dist(x):\n",
        "    for i in range(len(x)//10):\n",
        "        print(statistics.stdev(x[i]), statistics.mean(x[i]))"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbpBLETEO4cQ",
        "outputId": "95529ea0-7bd3-4b92-a167-839c5e595bab"
      },
      "source": [
        "math.sqrt(2/200)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbdpIc97lNX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6549cff-e584-4e2c-8fbe-0bd7b9dea321"
      },
      "source": [
        "check_dist(sample)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09403171521976275 0.013622055097298417\n",
            "0.11022747597801236 0.004275158318235466\n",
            "0.10391848009119782 -0.01736304265045632\n",
            "0.10158040902814837 -0.02140397506068278\n",
            "0.09882006911891293 -0.0053818314803667595\n",
            "0.10310174401159848 0.000929601684799433\n",
            "0.10590896519472498 -0.002986448136461439\n",
            "0.10860384191536261 -0.0019467197654269364\n",
            "0.10334640758604192 0.00022377121525137602\n",
            "0.10250798204880954 -0.005277651317013858\n",
            "0.09689419991073889 -0.011304377462247831\n",
            "0.10161001000236593 0.0012921971242199144\n",
            "0.10496614902299435 0.01890044117944085\n",
            "0.10825130611808448 0.0014377722556012744\n",
            "0.09529078477492108 -0.012941433333789797\n",
            "0.09452227869299638 0.0011131585828455986\n",
            "0.10649544360871815 -0.014153836025424677\n",
            "0.10728331890142034 0.011419162266351656\n",
            "0.09875726811080487 -0.008044575164524132\n",
            "0.10548583913595076 0.001835162672406242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzn9nF3VvGy_"
      },
      "source": [
        "## Matrix multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5YZMmARvxVq"
      },
      "source": [
        "Now that our data is ready, it is time to look at matrix multiplication, which is the most frequently used operation in deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5UBl8En3vfB"
      },
      "source": [
        "Here is my implementation of matrix multiplication. There are other ways to do it, but I found this to be the fastest so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Puhwa5kLgKYU"
      },
      "source": [
        "m1 = [[1, 2], [3, 4]]\n",
        "m2 = [[5, 4], [3, 2]]"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju4_4Qp38CA9"
      },
      "source": [
        "def py_matmul(a, b):\n",
        "    \"\"\" \n",
        "    Matrix multiplication \n",
        "    \"\"\"\n",
        "    ar,ac = len(a),len(a[0])\n",
        "    br,bc = len(b),len(b[0])\n",
        "    assert ac == br, f'Size of ar ({ac}) does not match br ({br}).'\n",
        "    c = lst_nums((ar, bc), 0)\n",
        "    t = transpose(b)\n",
        "    for i in range(ar):\n",
        "        c[i] = [sum(map(op.mul, a[i], t[j])) for j in range(bc)]\n",
        "    return c"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMV10ECl8MwK",
        "outputId": "c6932875-e16e-4463-8c08-7c422e881157"
      },
      "source": [
        "py_matmul(m1, m2)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[11, 8], [27, 20]]"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8NFy61QMtjX"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY_d1J1y6JFr"
      },
      "source": [
        "It is time to make a model to train. Let's briefly look at what they do. Each function has a forward pass and a backward pass. Backward pass finds gradients and allows us to use stochastic gradient descent (SGD). Stochastic gradient descent is how we can train our model automatically and get our random weights and biases closer to right numbers that will suit to our needs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMMJt994rcPQ"
      },
      "source": [
        "Relu turns negative number into zeros. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoglZw3xk8Uk"
      },
      "source": [
        "class Relu():\n",
        "    def forward(self, x):\n",
        "        self.old_x = x.copy()\n",
        "        res = map_mat(lambda y: 0 if y < 0 else y, x)\n",
        "        return res\n",
        "\n",
        "    def backward(self, grad):\n",
        "        res = map_mat(lambda x, g: g if x > 0 else 0, self.old_x, grad)\n",
        "        return res"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G6l5BGFsIS-"
      },
      "source": [
        "Softmax is used when there are many categories to predict. Our data has to predict ten categories, from zero to ten. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y3qvJER-OUD"
      },
      "source": [
        "class Softmax():\n",
        "    def forward(self, inp):\n",
        "        mat = map_mat(math.exp, inp)\n",
        "        self.old_y = []\n",
        "        for i in range(len(mat)):\n",
        "            s = sum(mat[i])\n",
        "            self.old_y.append([x/s for x in mat[i]])\n",
        "        return self.old_y\n",
        "    \n",
        "    def backward(self, grad):\n",
        "        res = map_mat(op.mul, self.old_y, grad)\n",
        "        res = [sum(res[i]) for i in range(len(self.old_y))] # shape is (64,)\n",
        "        return map_mat(op.mul, self.old_y, map_mat(op.sub, grad, res))"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iACluKZ0whlh"
      },
      "source": [
        "Cross entropy loss measures how well our model is doing, and from that, our model can get our weights and biases closer to better ones that will give us better predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1MpK31fAVHG"
      },
      "source": [
        "class CrossEntropy():\n",
        "    def forward(self, inp, targ):\n",
        "        mat = map_mat(lambda x: x if x>1e-8 else 1e-8, inp)\n",
        "        self.old_x = mat.copy()\n",
        "        self.old_y = targ\n",
        "        res = []\n",
        "        for i in range(len(mat)):\n",
        "            for j in range(len(targ[0])):\n",
        "                if targ[i][j] == 1:\n",
        "                    res.append(-math.log(mat[i][j]))\n",
        "        return res\n",
        "\n",
        "    def backward(self):\n",
        "        mat = map_mat(lambda x: x if x>1e-8 else 1e-8, self.old_x)\n",
        "        res = lst_nums(shape(mat), num=0.)\n",
        "        for i in range(len(mat)):\n",
        "            for j in range(len(self.old_y[0])):\n",
        "                if self.old_y[i][j] == 1:\n",
        "                    res[i][j] = (-1/(mat[i][j]))\n",
        "        return res"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKZk6Dnx0qdB"
      },
      "source": [
        "Linear is just matrix multiplication of our input, which is a matrix of images, and weights, which we initialize with random numbers. After a matrix multiplication, there is an addition of the result and bias, which are initialized to zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu9ijitQaa72"
      },
      "source": [
        "class Linear():\n",
        "    def __init__(self, n_in, n_out):\n",
        "        self.weights = lst_random((n_in, n_out), True) \n",
        "        self.biases = lst_nums((n_out), num=0)\n",
        "    \n",
        "    def forward(self, inp):\n",
        "        self.old_x = inp.copy()\n",
        "        return map_mat(lambda x, y: x + y, py_matmul(inp, self.weights), self.biases)\n",
        "    \n",
        "    def backward(self, grad):\n",
        "        self.grad_b = mean_0(grad)\n",
        "        self.grad_w = py_matmul(transpose(self.old_x), grad)\n",
        "        out = py_matmul(grad, transpose(self.weights))\n",
        "        return out"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qA9xrMZhUAC"
      },
      "source": [
        "def mean_0 (matrix):\n",
        "    \"Find a mean in matrix over 0 axis\"\n",
        "    return [statistics.mean([m[i] for m in matrix]) for i in range(len(matrix[0]))]"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnlvluFA2dcT"
      },
      "source": [
        "Here is our model. It has forward and backward, loss, and make_preds. This is how we combine our functions, or layers, for training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8nyZvUFc5E4"
      },
      "source": [
        "class Model():\n",
        "    def __init__(self, layers, cost):\n",
        "        self.layers = layers\n",
        "        self.cost = cost\n",
        "\n",
        "    def forward(self,x):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "    \n",
        "    def make_preds(self, x):\n",
        "        outputs = self.forward(x)   # (64, 10)\n",
        "        preds = [outputs[i].index(max(outputs[i])) for i in range(len(outputs))]\n",
        "        return preds\n",
        "\n",
        "    def loss(self,x,y):\n",
        "        return self.cost.forward(self.forward(x),y)\n",
        "\n",
        "    def backward(self):\n",
        "        grad = self.cost.backward()\n",
        "        for i in range(len(self.layers)-1,-1,-1):\n",
        "            grad = self.layers[i].backward(grad)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shWrMO-S4yCG"
      },
      "source": [
        "Here, by calling `load_minibatches`, we turn our training images and labels into little batches. This way, we can update our weights and biases more efficiently. If we try to update with the whole dataset, it is very slow. If we just use one image at a time, our model can get too biased, rather than being generalized over different kind of input. This returns a dataset, which is a set of images and labels combined together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eglJ7kXidNAc"
      },
      "source": [
        "def load_minibatches(trn, targets, bs=64):\n",
        "    \"\"\"\n",
        "    Turn our inputs and labels into a dataset \n",
        "    containing minibatches \n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for i in range((len(trn) // bs) - 1):\n",
        "        targs = lst_nums((bs, 10), 0)\n",
        "        targets_mb = targets[(i*bs) : ((i+1)*bs)]\n",
        "        for z in range(bs):\n",
        "            targs[z][targets_mb[z]] = 1.\n",
        "        data.append((trn[:bs],targs))\n",
        "    return data"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JP28gde9AKm",
        "outputId": "d98eaea6-fed3-42cf-8130-bda9ea82b102"
      },
      "source": [
        "dataset = load_minibatches(train_imgs, train_labels)\n",
        "shape(dataset)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8,)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFWlcBxr6ke6"
      },
      "source": [
        "This is our train function. It trains the model with training data with learning rate for epochs, and uses testset for validation. Learning rate is used to determine how fast we update our weights and biases. Epoch determines how many times the model sees the whole data. Here, `train` also calculates accuracy by making predictions from testset. This is important because we can see how well our model performs on data that it has not seen yet. After training for a while, even if our training loss can be reduced a lot, it could possibly have a high validation loss with testset. After all, what use does our model have if it only distinguish numbers it has seen before but not the new numbers?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kAD7h-WdDxq"
      },
      "source": [
        "def train(model,lr,nb_epoch,data, testset):\n",
        "    \"\"\" \n",
        "    Train our model \n",
        "    \"\"\"\n",
        "    for epoch in range(nb_epoch):\n",
        "        running_loss = 0.\n",
        "        num_inputs = 0\n",
        "        for mini_batch in data:\n",
        "            corrects = 0\n",
        "            inputs,targets = mini_batch\n",
        "            test_inp, test_targs = testset\n",
        "            num_inputs += len(inputs)\n",
        "            #Forward pass + compute loss\n",
        "            preds = model.make_preds(test_inp)\n",
        "            for i in range(len(preds)):\n",
        "                if test_targs[i] == preds[i]:\n",
        "                    corrects += 1\n",
        "            # print(corrects)\n",
        "            running_loss += sum(model.loss(inputs,targets))\n",
        "            #Back propagation\n",
        "            model.backward()\n",
        "            #Update of the parameters\n",
        "            for layer in model.layers:\n",
        "                if type(layer) == Linear:\n",
        "                    weight_diff = [list(map(lambda x: x * lr, layer.grad_w[i])) for i in range(len(layer.grad_w))]\n",
        "                    layer.weights = map_mat(op.sub, layer.weights, weight_diff)\n",
        "                    bias_diff = list(map(lambda x: x * lr, layer.grad_b))\n",
        "                    layer.biases = map_mat(op.sub, layer.biases, bias_diff)\n",
        "            # print(f'loss = {running_loss/num_inputs}, Accuracy = {corrects*100 / len(preds)}')\n",
        "        print(f'Epoch {epoch+1}/{nb_epoch}: loss = {running_loss/num_inputs}, Accuracy = {corrects*100 / len(preds)}')"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xshw7xci-Lzp"
      },
      "source": [
        "Here is our neural net with different layers. By using `Model`, we can easily make new model and try out how they perform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKp3ASITdDBY"
      },
      "source": [
        "net = Model([Linear(784,60), Relu(), Linear(60,10), Softmax()], CrossEntropy())"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZgqY_oR-m9f"
      },
      "source": [
        "Now we finally train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4mUVCjlj6HC",
        "outputId": "d9fca993-0c68-4288-8a1d-36f39a41a2a4"
      },
      "source": [
        "train(net, 0.01, 3, dataset, (test_imgs, test_labels))"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3: loss = 2.378668682344605, Accuracy = 32.0\n",
            "Epoch 2/3: loss = 2.244675878898528, Accuracy = 33.0\n",
            "Epoch 3/3: loss = 2.2046788634640855, Accuracy = 35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtFj_OUe-pMR"
      },
      "source": [
        "We are done with training. How can we do better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB9oumrSBjEl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
